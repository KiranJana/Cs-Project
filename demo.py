# -*- coding: utf-8 -*-
"""Demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1namSsbvbZp037-6_C5L7WEyrVrggaMhG
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)
# %cd gdrive/MyDrive/Demo/0a3e2b67-5126-4c30-8a51-7f854d3f97d0/candidates

import os

file_list = os.listdir()

from natsort import natsorted
sorted_list_file = natsorted(file_list)

resumes = []
for sorted_files in sorted_list_file:
  for file in os.listdir():
    if file == sorted_files:
      if not file.endswith('Job_Description.txt'):     
        file = open(file, 'r')
        resume = file.read()
        resumes.append(resume)

!pip3 install sentence-transformers

import sentence_transformers 
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import numpy as np
import pandas as pd

from sklearn.metrics.pairwise import cosine_similarity

desc_file = open('Job_Description.txt', 'r')
job_desc_text = desc_file.read()

model1 = SentenceTransformer('bert-base-nli-mean-tokens')

scores = []
for i in range(0,len(resumes)):
    documents1 = [job_desc_text, resume[i]]

    text_embeddings1 = model1.encode(documents1, show_progress_bar = True)
    similarities1 = cosine_similarity(text_embeddings1)
    similarities_sorted1 = similarities1.argsort()
    id_1 = []
    id_2 = []
    score = []
    temp = (similarities1[0][similarities_sorted1[-2]])
    scores.append(temp[0])
    print(scores)
    for index,array in enumerate(similarities_sorted1):
        id_1.append(index)
        id_2.append(array[-2])
        score.append(similarities1[index][array[-2]])
    index_df1 = pd.DataFrame({'id_1' : id_1,
                          'id_2' : id_2,
                          'score' : score})
    print(index_df1)

import matplotlib.pyplot as plt

plt.plot(scores)
print(scores)

dictionary_created = {}
for index in range(0, len(resumes)):
  dictionary_created['Res' + str(index+1) + '.txt'] = scores[index]


sorted_dict = sorted(dictionary_created.items(), key = lambda x:x[1], reverse = True)
created_dict = {t[0]: t[1] for t in sorted_dict}
created_dict

model2= SentenceTransformer('all-MiniLM-L6-v2')

scores = []
for i in range(0,len(resumes)):
    documents1 = [job_desc_text, resume[i]]

    text_embeddings1 = model2.encode(documents1, show_progress_bar = True)
    similarities1 = cosine_similarity(text_embeddings1)
    similarities_sorted1 = similarities1.argsort()
    id_1 = []
    id_2 = []
    score = []
    temp = (similarities1[0][similarities_sorted1[-2]])
    scores.append(temp[0])
    print(scores)
    for index,array in enumerate(similarities_sorted1):
        id_1.append(index)
        id_2.append(array[-2])
        score.append(similarities1[index][array[-2]])
    index_df1 = pd.DataFrame({'id_1' : id_1,
                          'id_2' : id_2,
                          'score' : score})
    print(index_df1)

dictionary_created = {}
for index in range(0, len(resumes)):
  dictionary_created['Res' + str(index+1) + '.txt'] = scores[index]


sorted_dict = sorted(dictionary_created.items(), key = lambda x:x[1], reverse = True)
created_dict = {t[0]: t[1] for t in sorted_dict}
created_dict

model3 = SentenceTransformer('nli-distilroberta-base-v2')

scores = []
for i in range(0,len(resumes)):
    documents1 = [job_desc_text, resume[i]]

    text_embeddings1 = model3.encode(documents1, show_progress_bar = True)
    similarities1 = cosine_similarity(text_embeddings1)
    similarities_sorted1 = similarities1.argsort()
    id_1 = []
    id_2 = []
    score = []
    temp = (similarities1[0][similarities_sorted1[-2]])
    scores.append(temp[0])
    print(scores)
    for index,array in enumerate(similarities_sorted1):
        id_1.append(index)
        id_2.append(array[-2])
        score.append(similarities1[index][array[-2]])
    index_df1 = pd.DataFrame({'id_1' : id_1,
                          'id_2' : id_2,
                          'score' : score})
    print(index_df1)

dictionary_created = {}
for index in range(0, len(resumes)):
  dictionary_created['Res' + str(index+1) + '.txt'] = scores[index]


sorted_dict = sorted(dictionary_created.items(), key = lambda x:x[1], reverse = True)
created_dict = {t[0]: t[1] for t in sorted_dict}
created_dict

import json