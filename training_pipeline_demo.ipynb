{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1066deb7-c30e-48ed-9436-758829fc79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "import re\n",
    "import random\n",
    "\n",
    "from training_data import TrainingData\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7a8bb2-1e5c-4ac3-899b-3e6ff0c04ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def get_transform_data(load_path: str, source: str) -> list[str]:\n",
    "    if source == \"GCS\":\n",
    "        load_path = f\"gs://{load_path}\"\n",
    "    data = pd.read_parquet(load_path)\n",
    "    text_data = data[\"text\"].to_list()\n",
    "    # more preprocessing can be applied\n",
    "    processed_data = [re.sub(\"\\s\\s+\", \" \", t) for t in text_data] \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e7d809-4a12-4b60-ad74-5e139ecf2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['startdate_ml/scraped_data/test_parser_data_2022-09-08 18_18_19.parquet', 'startdate_ml/scraped_data/test_parser_data_2022-09-08 18_32_19.parquet']\n",
      "Info: no ner component in pipeline\n",
      "Info: no ner component in pipeline\n"
     ]
    }
   ],
   "source": [
    "# download scraped data from GCS bucket for prelabelling via spacy ruler\n",
    "# 1. creates TrainingData class instance and can be applied on multiple parquet files in GCS bucket\n",
    "# glob folder for .parquet files\n",
    "# if GOOGLE CREDENTIALS PATH in config, use it\n",
    "try:\n",
    "    fs = gcsfs.GCSFileSystem(token = config.GOOGLE_CREDENTIALS_PATH)\n",
    "except:\n",
    "    # if not, fall back to environment variable\n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "files_list = [f for f in fs.ls(config.SCRAPED_DATA_BUCKET) if \".parquet\" in f]\n",
    "print(files_list)\n",
    "\n",
    "# process files and move to processed in GCS\n",
    "training_data_list = []\n",
    "for file in files_list:\n",
    "    data = get_transform_data(file, \"GCS\")  \n",
    "    labeled = TrainingData.pre_label_data(data, config.RULES_BUCKET_NAME, config.RULES_BLOB_NAME)\n",
    "    training_data_list.append(labeled)\n",
    "    # remove from bucket if processed\n",
    "    # disabled for testing\n",
    "    '''\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    fs.move(path1=file, path2=f\"{config.PROCESSED_FILES_BUCKET}/{file_name}\")\n",
    "    '''\n",
    "\n",
    "# merge training data (controlled for duplicates) to get all pre-labeled data\n",
    "training_data = TrainingData.merge(training_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1275cfd8-a5ae-4952-8df9-dd247bea7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE, total time (s)=2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\libor\\.virtualenvs\\SpacyTransformers-lu3y5lsq\\lib\\site-packages\\labelbox\\data\\annotation_types\\classification\\classification.py:85: UserWarning: Dropdown classification is deprecated and will be removed in a future release\n",
      "  warnings.warn(\"Dropdown classification is deprecated and will be \"\n",
      "C:\\Users\\libor\\.virtualenvs\\SpacyTransformers-lu3y5lsq\\lib\\site-packages\\labelbox\\data\\annotation_types\\label.py:142: UserWarning: This method is deprecated and will be removed in a future release. Feature schema ids are no longer required for importing.\n",
      "  warnings.warn(\"This method is deprecated and will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time=27.98, Time per item=1.55\n"
     ]
    }
   ],
   "source": [
    "# 2. upload to labelbox for manual labelling (for all or parts of the data)\n",
    "# thi scan be skipped \n",
    "# randomize the data inside the TrainingData class (list)\n",
    "random.shuffle(training_data.data)\n",
    "# upload to Labelbox\n",
    "training_data.upload_data_to_labelbox(config.LABELBOX_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c41827-00ec-48a0-af75-9179959be3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. when manually labeled, download\n",
    "# note project must be completely labeled to be downloaded\n",
    "verified_training_data = TrainingData.from_labelbox_data(config.LABELBOX_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340090a9-bda6-44f2-8b0d-38cb294c65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs binary data saved to location gs://startdate_ml/spacy_docs/training_data.spacy\n"
     ]
    }
   ],
   "source": [
    "# 4. convert to spacy training data and save  \n",
    "# tranform to spacy training data format (list of docs) and dump for load by training script (now in colab)\n",
    "verified_training_data.transform_to_spacy_and_save_docs(config.SPACY_TRAINING_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d594e6aa-0f40-4a15-bb56-7a49154fd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train RoBERTa model on training data\n",
    "# The training itself is managed in Colab for performance reasons\n",
    "# colab notebook: https://colab.research.google.com/drive/1vhXS2GnUE56m7mZTyc43t9wHrqqRezdj?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb66e8-15d1-4da0-9f1b-3646b5ae91f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpacyTransformers",
   "language": "python",
   "name": "spacytransformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
